{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "import tensorflow as tf\n",
    "import json\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 50, 50, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 50, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 25, 25, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 23, 23, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               3965440   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 4,032,034\n",
      "Trainable params: 4,032,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "global model\n",
    "global graph\n",
    "\n",
    "with open(\"../Image_Recognizer/model.json\", \"r\") as json_file:\n",
    "    model = model_from_json(json_file.read())\n",
    "    model.load_weights(\"../Image_Recognizer/model.h5\")\n",
    "    graph = tf.get_default_graph()\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = None\n",
    "\n",
    "class Analysis_Thread(threading.Thread):\n",
    "    def __init__(self):\n",
    "        threading.Thread.__init__(self)\n",
    "\n",
    "    def run(self):\n",
    "        while (not(frame is None)):\n",
    "            self.Predict_frame(frame)\n",
    "\n",
    "    def ResizeImage(self, image):\n",
    "        return np.array(Image.fromarray(image, 'RGB').resize((50, 50)))\n",
    "\n",
    "    def Get_frame_name(self, label):\n",
    "        if label == 0:\n",
    "            return \"cow\"\n",
    "        elif label == 1:\n",
    "            return \"not cow\"\n",
    "    \n",
    "    def Predict_frame(self, frame):\n",
    "        with graph.as_default():\n",
    "            score = model.predict(np.array([self.ResizeImage(frame)/255]), verbose=1)\n",
    "            label_index = np.argmax(score)\n",
    "            accuracy = np.max(score)\n",
    "            print(str(count) + \": \" + self.Get_frame_name(label_index) + \" with accuracy = \" + str(accuracy))\n",
    "            cv2.imwrite(\"data/Processed/\" + str(count) + \".jpg\", frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "2: cow with accuracy = 0.6050858\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "3: not cow with accuracy = 0.9161762\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "4: not cow with accuracy = 0.7004037\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "5: cow with accuracy = 0.9404437\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "6: not cow with accuracy = 0.9342666\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "8: cow with accuracy = 0.5628162\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "12: cow with accuracy = 0.9977563\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "14: cow with accuracy = 0.9850515\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "14: cow with accuracy = 0.88294035\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "16: cow with accuracy = 0.9897625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "18: cow with accuracy = 0.9113221\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "19: cow with accuracy = 0.8666692\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "21: not cow with accuracy = 0.6858468\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "22: cow with accuracy = 0.75401396\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "23: cow with accuracy = 0.72984093\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "25: cow with accuracy = 0.9998671\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "27: cow with accuracy = 0.9999938\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "28: cow with accuracy = 0.9999963\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "30: cow with accuracy = 0.99999964\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "31: cow with accuracy = 0.9999224\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "35: cow with accuracy = 0.55576277\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "37: cow with accuracy = 0.7186002\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "38: cow with accuracy = 0.7397234\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "40: cow with accuracy = 0.73721975\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "41: cow with accuracy = 0.73721975\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "42: cow with accuracy = 0.72346807\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "vidcap = cv2.VideoCapture(\"data/Raw/cow/videoplayback.mp4\")\n",
    "success, frame = vidcap.read()\n",
    "\n",
    "keras_thread = Analysis_Thread()\n",
    "keras_thread.start()\n",
    "\n",
    "while success:\n",
    "    vidcap.set(cv2.CAP_PROP_POS_MSEC,(count*1000))\n",
    "    success, frame = vidcap.read()\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
